{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NYU CDS\n",
    "\n",
    "### Fall 2021\n",
    "\n",
    "### Introduction to Data Science\n",
    "\n",
    "### Project 2\n",
    "\n",
    "### student netid: \n",
    "\n",
    "### deadline: Dec 06, 2021, 11:59pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data analysis Project 2\n",
    "### Correlation and Regression of Movie Ratings Data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset description\n",
    "\n",
    "This dataset features ratings data of 400 movies from 1097 research participants. \n",
    "\n",
    "* 1st row: Headers (Movie titles/questions) â€“ note that the indexing in this list is from 1\n",
    "* Row 2-1098: Responses from individual participants\n",
    "* Columns 1-400: These columns contain the ratings for the 400 movies (0 to 4, and missing)\n",
    "* Columns 401-421: These columns contain self-assessments on sensation seeking behaviors (1-5)\n",
    "* Columns 422-464: These columns contain responses to personality questions (1-5)\n",
    "* Columns 465-474: These columns contain self-reported movie experience ratings (1-5)\n",
    "* Column 475: Gender identity (1 = female, 2 = male, 3 = self-described)\n",
    "* Column 476: Only child (1 = yes, 0 = no, -1 = no response)\n",
    "* Column 477: Movies are best enjoyed alone (1 = yes, 0 = no, -1 = no response)\n",
    "\n",
    "Note that we did most of the data munging for you already (e.g. Python interprets commas in a csv file as separators, so we removed all commas from movie titles), but you still need to handle missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Q1:\n",
    "\n",
    "\n",
    "**Note:** For all missing values in the data, use the average of the corresponding column so to fill in the missing data. \n",
    "\n",
    "\n",
    "\n",
    "In this problem, under **the most correlated**, we consider the largest correlation in the absolute value.\n",
    "\n",
    "\n",
    "1.1. For every user in the given data, find its most correlated user. \n",
    "\n",
    "1.2. What is the pair of the most correlated users in the data? \n",
    "\n",
    "1.3. What is the value of this highest correlation?\n",
    "\n",
    "1.4. For users 0, 1, 2, \\dots, 9, print their most correlated users. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "data = np.genfromtxt('movieReplicationSet.csv', delimiter = ',',skip_header = 1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.corrcoef(data,rowvar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = []\n",
    "count = 0\n",
    "sum = 0\n",
    "a = np.empty((1098,400))\n",
    "for i in range(400):\n",
    "    temp = data[:,i:i+1]\n",
    "    temp2  = np.isfinite(data[:,i:i+1])\n",
    "    temp = temp[temp2]\n",
    "    avg = np.mean(temp)\n",
    "    \n",
    "    for j in range(len(temp2)):\n",
    "        if temp2[j] == True:\n",
    "            a[j][i] = data[j,i]\n",
    "        else:\n",
    "            a[j][i] = avg\n",
    "a = a.T \n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r,c =a.shape\n",
    "print(r)\n",
    "max= 0\n",
    "index = (0,1)\n",
    "\n",
    "#print(a)\n",
    "X = np.empty((r,2))\n",
    "for i in range(c):\n",
    "    for j in range(i+1,c):\n",
    "        if j == 897 and i==0:\n",
    "            continue\n",
    "        X[:,0:1] = a[:,i:i+1]\n",
    "        X[:,1:2] = a[:,j:j+1]\n",
    "        corr = np.corrcoef(X.T)\n",
    "        print((i,j),end=\" \")\n",
    "        print(corr[0][1])\n",
    "        if np.abs(corr[0][1]) > max:\n",
    "            max = corr[0][1]\n",
    "            index = (i,j)\n",
    "print(index,end=\" \")\n",
    "print(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.corrcoef(a,rowvar=False)[0][583])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2:\n",
    "\n",
    "We want to find a model between the ratings and the personal part of the data. To do so, consider:\n",
    "\n",
    "\n",
    "**Part 1**: the ratings of all users over columns 1-400: \n",
    "\n",
    "-- Columns 1-400: These columns contain the ratings for the 400 movies (0 to 4, and missing);\n",
    "\n",
    "call this part `df_rate`\n",
    "\n",
    "\n",
    "and \n",
    "\n",
    "\n",
    "**Part 2**:  the part of the data which includes all users over columns 401-474\n",
    "\n",
    "-- Columns 401-421: These columns contain self-assessments on sensation seeking behaviors (1-5)\n",
    "\n",
    "-- Columns 422-464: These columns contain responses to personality questions (1-5)\n",
    "\n",
    "-- Columns 465-474: These columns contain self-reported movie experience ratings (1-5)\n",
    "\n",
    "call this part `df_pers`.\n",
    "\n",
    "---\n",
    "\n",
    "Our main task is to model: \n",
    "\n",
    "\n",
    "`df_pers = function(df_rate)`\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Note:** Split the original data into training and testing as the ratio 0.80: 0.20. \n",
    "\n",
    "\n",
    "2.1. Model `df_pers = function(df_rate)` by using the linear regression. \n",
    "\n",
    "What are the errors on: (i) the training part; (ii) the testing part?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2.2. Model `df_pers = function(df_rate)` by using the ridge regression with hyperparamter values alpha from [0.0, 1e-8, 1e-5, 0.1, 1, 10]. \n",
    "\n",
    "For every of the previous values for alpha, what are the errors on: (i) the training part; (ii) the testing part?\n",
    "\n",
    "What is a best choice for alpha?\n",
    "\n",
    "\n",
    "\n",
    "2.3. Model `df_pers = function(df_rate)` by using the lasso regression with hyperparamter values alpha from [1e-3, 1e-2, 1e-1, 1]. \n",
    "\n",
    "For every of the previous values for alpha, what are the errors on: (i) the training part; (ii) the testing part?\n",
    "\n",
    "What is a best choice for alpha?\n",
    "\n",
    "\n",
    "**Note**: Ignore any `convergence warning` in case you may obtain in the Lasso regression.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = []\n",
    "count = 0\n",
    "sum = 0\n",
    "b = np.empty((1098,74))\n",
    "for i in range(400,474):\n",
    "    temp = data[:,i:i+1]\n",
    "    temp2  = np.isfinite(data[:,i:i+1])\n",
    "    temp = temp[temp2]\n",
    "    avg = np.mean(temp)\n",
    "    \n",
    "    for j in range(len(temp2)):\n",
    "        if temp2[j] == True:\n",
    "            b[j][i-400] = data[j,i]\n",
    "        else:\n",
    "            b[j][i-400] = avg\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# split a dataset into train and test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# create dataset\n",
    "X, y = a.T[:,0:400],b[:,0:74]\n",
    "print(y)\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "regr = linear_model.LinearRegression() # linearRegression function from linear_model\n",
    "regr.fit(X_train,y_train) # use fit method \n",
    "y_pred = regr.predict(X_test)\n",
    "y_tpred = regr.predict(X_train)\n",
    "rSqr = regr.score(X_train,y_train)\n",
    "print(rSqr)\n",
    "rSqr = regr.score(X_test,y_test)\n",
    "print(\"Test error:\", mean_squared_error(y_pred,y_test))\n",
    "print(\"Train error:\", mean_squared_error(y_tpred,y_train))\n",
    "print(rSqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "lst = [1e-8,1e-5,0,0.1, 1,10]\n",
    "for i in lst:\n",
    "    reg = linear_model.Ridge(alpha=i)\n",
    "    clf = reg.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_tpred = clf.predict(X_train)\n",
    "    print(\"Test error:\", mean_squared_error(y_pred,y_test), end=\" \")\n",
    "    print(\"Train error:\", mean_squared_error(y_tpred,y_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [1e-8,1e-5,0.1,0, 1,10]\n",
    "from sklearn.linear_model import Lasso\n",
    "for i in lst:\n",
    "    reg = Lasso(alpha=i)\n",
    "    clf = reg.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_tpred = clf.predict(X_train)\n",
    "    print(\"Test error:\", mean_squared_error(y_pred,y_test), end=\" \")\n",
    "    print(\"Train error:\", mean_squared_error(y_tpred,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
